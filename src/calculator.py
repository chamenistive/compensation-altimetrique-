"""
Module de calculs pour la compensation altim√©trique.

Ce module contient tous les algorithmes de calcul pour le nivellement
g√©om√©trique avec une pr√©cision garantie de 2mm.

Algorithmes impl√©ment√©s:
- Calcul des d√©nivel√©es: Œîh = AR - AV
- Calcul des altitudes par propagation
- Calcul des poids selon la th√©orie g√©od√©sique
- Validation des contr√¥les et fermetures

Formules g√©od√©siques:
- Variance d'observation: œÉ¬≤ = a¬≤ + b¬≤√ód (mm¬≤)
- Tol√©rance de fermeture: T = 4√ó‚àöK (mm)
- Poids: P = 1/œÉ¬≤

Auteur: Syst√®me de Compensation Altim√©trique
Version: 1.0
Pr√©cision: 2mm
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Optional, Union
from dataclasses import dataclass, field
from enum import Enum

from exceptions import (
    CalculationError, PrecisionError, validate_positive_number,
    safe_divide, validate_distance_km
)
from validators import GeodeticValidator, PrecisionValidator
from atmospheric_corrections import (
    AtmosphericCorrector, AtmosphericConditions, create_standard_conditions
)
from atmospheric_corrections import (
    AtmosphericCorrector, AtmosphericConditions, create_standard_conditions
)
from atmospheric_corrections import (
    AtmosphericCorrector, AtmosphericConditions, create_standard_conditions
)
from atmospheric_corrections import (
    AtmosphericCorrector, AtmosphericConditions, create_standard_conditions
)
from atmospheric_corrections import (
    AtmosphericCorrector, AtmosphericConditions, create_standard_conditions
)
from atmospheric_corrections import (
    AtmosphericCorrector, AtmosphericConditions, create_standard_conditions
)


class TraverseType(Enum):
    """Types de cheminement."""
    CLOSED = "ferm√©"
    OPEN = "ouvert"
    UNKNOWN = "ind√©termin√©"


@dataclass
class HeightDifference:
    """R√©sultat du calcul d'une d√©nivel√©e."""
    delta_h_m: float
    ar_reading: float
    av_reading: float
    instrument_id: int
    is_valid: bool = True
    control_residual: Optional[float] = None


@dataclass
class AltitudeCalculation:
    """R√©sultat du calcul d'altitude."""
    point_id: str
    altitude_m: float
    cumulative_delta_h: float
    is_reference: bool = False


@dataclass
class ClosureAnalysis:
    """Analyse de fermeture du cheminement."""
    traverse_type: TraverseType
    closure_error_m: float
    closure_error_mm: float
    tolerance_mm: float
    total_distance_km: float
    is_acceptable: bool
    precision_ratio: float


@dataclass
class CalculationResults:
    """R√©sultats complets des calculs."""
    height_differences: List[HeightDifference]
    altitudes: List[AltitudeCalculation]
    closure_analysis: ClosureAnalysis
    control_statistics: Dict
    calculation_metadata: Dict = field(default_factory=dict)


class HeightDifferenceCalculator:
    """
    Calculateur de d√©nivel√©es pour nivellement g√©om√©trique.
    
    Impl√©mente la formule fondamentale: Œîh = AR - AV
    avec validation et contr√¥le de qualit√©.
    """
    
    def __init__(self, precision_mm: float = 2.0):
        self.precision_mm = precision_mm
        self.precision_m = precision_mm / 1000.0
    
    def calculate_height_differences(self, df: pd.DataFrame, 
                                   ar_columns: List[str], 
                                   av_columns: List[str]) -> List[HeightDifference]:
        """
        Calcul des d√©nivel√©es pour toutes les observations.
        
        Algorithme:
        1. Pour chaque paire AR/AV: Œîh = AR - AV
        2. Validation des lectures (plage r√©aliste)
        3. Calcul du contr√¥le si plusieurs instruments
        
        Args:
            df: DataFrame avec les observations
            ar_columns: Colonnes des lectures arri√®re
            av_columns: Colonnes des lectures avant
            
        Returns:
            List[HeightDifference]: D√©nivel√©es calcul√©es
        """
        if len(ar_columns) != len(av_columns):
            raise CalculationError(
                "Nombre incoh√©rent de colonnes AR et AV",
                calculation_type="height_differences",
                input_values={'ar_count': len(ar_columns), 'av_count': len(av_columns)}
            )
        
        height_differences = []
        
        for index, row in df.iterrows():
            row_deltas = []
            
            # Calcul pour chaque instrument
            for inst_id, (ar_col, av_col) in enumerate(zip(ar_columns, av_columns), 1):
                ar_reading = pd.to_numeric(row[ar_col], errors='coerce')
                av_reading = pd.to_numeric(row[av_col], errors='coerce')
                
                if pd.notna(ar_reading) and pd.notna(av_reading):
                    # Validation des lectures
                    self._validate_readings(ar_reading, av_reading, index)
                    
                    # Calcul de la d√©nivel√©e
                    delta_h = ar_reading - av_reading
                    
                    height_diff = HeightDifference(
                        delta_h_m=delta_h,
                        ar_reading=ar_reading,
                        av_reading=av_reading,
                        instrument_id=inst_id,
                        is_valid=True
                    )
                    
                    row_deltas.append(height_diff)
                    height_differences.append(height_diff)
            
            # Calcul du contr√¥le si plusieurs instruments
            if len(row_deltas) > 1:
                self._calculate_control_residuals(row_deltas, index)
        
        return height_differences
    
    def _validate_readings(self, ar: float, av: float, row_index: int):
        """Validation des lectures AR et AV pour donn√©es r√©elles."""
        # Plage √©largie pour donn√©es r√©elles (terrain peut avoir de grosses d√©nivel√©es)
        min_reading, max_reading = -50.0, 50.0
        
        # Validation moins stricte - juste avertissements
        if not (min_reading <= ar <= max_reading):
            print(f"‚ö†Ô∏è Lecture AR inhabituelle √† la ligne {row_index}: {ar:.3f}m")
        
        if not (min_reading <= av <= max_reading):
            print(f"‚ö†Ô∏è Lecture AV inhabituelle √† la ligne {row_index}: {av:.3f}m")
        
        # Validation critique seulement pour valeurs extr√™mes
        if abs(ar) > 100 or abs(av) > 100:
            raise CalculationError(
                f"Lecture critique √† la ligne {row_index}: AR={ar}, AV={av}",
                calculation_type="reading_validation",
                input_values={'ar_reading': ar, 'av_reading': av, 'row': row_index}
            )
    
    def _calculate_control_residuals(self, row_deltas: List[HeightDifference], row_index: int):
        """Calcul des r√©sidus de contr√¥le entre instruments - version robuste."""
        if len(row_deltas) < 2:
            return
        
        # R√©sidu = diff√©rence entre les d√©nivel√©es des diff√©rents instruments
        delta_values = [hd.delta_h_m for hd in row_deltas]
        mean_delta = np.mean(delta_values)
        
        for i, height_diff in enumerate(row_deltas):
            residual = height_diff.delta_h_m - mean_delta
            height_diff.control_residual = residual
            
            # Tol√©rance progressive selon la distance et conditions
            # Donn√©es r√©elles peuvent avoir plus d'√©cart
            tolerance_mm = max(10.0, 0.005 * 1000)  # 10mm minimum ou 5mm/km
            
            if abs(residual * 1000) > tolerance_mm:
                print(f"‚ö†Ô∏è Contr√¥le ligne {row_index}: r√©sidu {residual*1000:.1f}mm > {tolerance_mm:.1f}mm")
                # Ne pas invalider automatiquement - garder comme avertissement
                # height_diff.is_valid = False
    
    def get_mean_height_differences(self, height_differences: List[HeightDifference]) -> pd.Series:
        """Calcul des d√©nivel√©es moyennes par point."""
        # Grouper par index de ligne (implicite dans l'ordre)
        df_deltas = pd.DataFrame([
            {
                'delta_h': hd.delta_h_m,
                'instrument': hd.instrument_id,
                'valid': hd.is_valid
            }
            for hd in height_differences
        ])
        
        # Moyenner les d√©nivel√©es valides pour chaque point
        mean_deltas = []
        current_group = []
        
        for hd in height_differences:
            if hd.instrument_id == 1:  # Nouveau point
                if current_group:
                    valid_deltas = [h.delta_h_m for h in current_group if h.is_valid]
                    mean_delta = np.mean(valid_deltas) if valid_deltas else np.nan
                    mean_deltas.append(mean_delta)
                current_group = [hd]
            else:
                current_group.append(hd)
        
        # Traiter le dernier groupe
        if current_group:
            valid_deltas = [h.delta_h_m for h in current_group if h.is_valid]
            mean_delta = np.mean(valid_deltas) if valid_deltas else np.nan
            mean_deltas.append(mean_delta)
        
        return pd.Series(mean_deltas)


class AltitudeCalculator:
    """
    Calculateur d'altitudes par propagation.
    
    Impl√©mente la propagation d'altitude depuis un point de r√©f√©rence
    avec optimisation vectorielle pour les performances.
    """
    
    def __init__(self, precision_mm: float = 2.0):
        self.precision_mm = precision_mm
        self.precision_m = precision_mm / 1000.0
    
    def calculate_altitudes(self, initial_altitude: float, 
                          delta_h_series: pd.Series,
                          point_ids: pd.Series) -> List[AltitudeCalculation]:
        """
        Calcul vectoris√© des altitudes.
        
        Algorithme optimis√©:
        H‚ÇÄ = altitude de r√©f√©rence
        H·µ¢ = H‚ÇÄ + Œ£(Œîh‚±º) pour j=1 √† i
        
        Args:
            initial_altitude: Altitude du point de r√©f√©rence
            delta_h_series: S√©rie des d√©nivel√©es
            point_ids: Identifiants des points
            
        Returns:
            List[AltitudeCalculation]: Altitudes calcul√©es
        """
        validate_positive_number(initial_altitude, "altitude_initiale", allow_zero=True)
        
        # Nettoyage des d√©nivel√©es (remplacer NaN par 0)
        delta_h_clean = delta_h_series.fillna(0)
        
        # Calcul vectoris√© avec cumsum
        cumulative_deltas = np.concatenate([[0], np.cumsum(delta_h_clean)])
        altitudes = initial_altitude + cumulative_deltas
        
        # Construction de la liste des r√©sultats
        altitude_calculations = []
        
        for i, (point_id, altitude) in enumerate(zip(point_ids, altitudes)):
            calc = AltitudeCalculation(
                point_id=str(point_id),
                altitude_m=round(altitude, 3),  # Arrondi √† 1mm
                cumulative_delta_h=round(cumulative_deltas[i], 3),
                is_reference=(i == 0)
            )
            altitude_calculations.append(calc)
        
        return altitude_calculations
    
    def validate_altitude_consistency(self, altitudes: List[AltitudeCalculation]) -> Dict:
        """Validation de la coh√©rence des altitudes calcul√©es."""
        altitude_values = [alt.altitude_m for alt in altitudes]
        
        statistics = {
            'min_altitude': min(altitude_values),
            'max_altitude': max(altitude_values),
            'altitude_range': max(altitude_values) - min(altitude_values),
            'total_elevation_change': altitudes[-1].cumulative_delta_h,
            'reference_altitude': altitudes[0].altitude_m
        }
        
        # Validations
        warnings = []
        
        if statistics['altitude_range'] > 1000:  # Plus de 1000m de d√©nivel√©e
            warnings.append(f"D√©nivel√©e importante: {statistics['altitude_range']:.1f}m")
        
        if any(alt < -500 or alt > 5000 for alt in altitude_values):  # Altitudes irr√©alistes
            warnings.append("Altitudes hors plage normale (-500m √† 5000m)")
        
        statistics['warnings'] = warnings
        return statistics


class WeightCalculator:
    """
    Calculateur de poids selon la th√©orie g√©od√©sique.
    
    Impl√©mente la formule de variance th√©orique:
    œÉ¬≤ = a¬≤ + b¬≤√ód (mm¬≤)
    o√π a = erreur instrumentale, b = erreur kilom√©trique, d = distance
    """
    
    def __init__(self, instrumental_error_mm: float = 0.2,
                 kilometric_error_mm: float = 0.3):
        """
        Args:
            instrumental_error_mm: Erreur instrumentale (mm)
            kilometric_error_mm: Erreur kilom√©trique (mm/km)
        """
        self.a_mm = instrumental_error_mm
        self.b_mm_per_km = kilometric_error_mm
        self.geodetic_validator = GeodeticValidator()
    
    def calculate_weights(self, distances_m: pd.Series) -> np.ndarray:
        """
        Calcul des poids g√©od√©siques.
        
        Algorithme:
        1. Conversion distances en km
        2. Calcul variance: œÉ¬≤ = a¬≤ + b¬≤√ód
        3. Calcul poids: P = 1/œÉ¬≤
        
        Args:
            distances_m: Distances en m√®tres
            
        Returns:
            np.ndarray: Matrice diagonale des poids
        """
        # Validation des distances
        validation_result = self.geodetic_validator.validate_distances(distances_m)
        if not validation_result.is_valid:
            raise CalculationError(
                f"Distances invalides: {'; '.join(validation_result.errors)}",
                calculation_type="weight_calculation"
            )
        
        weights = []
        
        for distance_m in distances_m:
            if pd.isna(distance_m) or distance_m <= 0:
                distance_m = 10.0  # Distance par d√©faut: 10m
            
            # Conversion en kilom√®tres
            distance_km = distance_m / 1000.0
            
            # Calcul de la variance (mm¬≤)
            variance_mm2 = self.a_mm**2 + (self.b_mm_per_km * distance_km)**2
            
            # Calcul du poids (1/variance)
            weight = safe_divide(1.0, variance_mm2, "calcul_poids")
            weights.append(weight)
        
        return np.diag(weights)
    
    def get_weight_statistics(self, weights: np.ndarray) -> Dict:
        """Statistiques des poids calcul√©s."""
        diagonal_weights = np.diag(weights)
        
        return {
            'min_weight': np.min(diagonal_weights),
            'max_weight': np.max(diagonal_weights),
            'mean_weight': np.mean(diagonal_weights),
            'std_weight': np.std(diagonal_weights),
            'weight_ratio': np.max(diagonal_weights) / np.min(diagonal_weights)
        }


class ClosureCalculator:
    """
    Calculateur de fermeture pour cheminements.
    
    Analyse la fermeture des cheminements ferm√©s ou ouverts
    selon les normes g√©od√©siques.
    """
    
    def __init__(self, precision_mm: float = 2.0):
        self.precision_mm = precision_mm
        self.precision_validator = PrecisionValidator(precision_mm)
    
    def analyze_closure(self, altitudes: List[AltitudeCalculation],
                       total_distance_km: float,
                       known_final_altitude: Optional[float] = None) -> ClosureAnalysis:
        """
        Analyse compl√®te de la fermeture du cheminement.
        
        Algorithme:
        1. D√©termination du type (ferm√©/ouvert)
        2. Calcul de l'erreur de fermeture
        3. Calcul de la tol√©rance: T = 4√ó‚àöK (mm)
        4. Validation selon les normes
        
        Args:
            altitudes: Liste des altitudes calcul√©es
            total_distance_km: Distance totale du cheminement
            known_final_altitude: Altitude connue du point final (si ouvert)
            
        Returns:
            ClosureAnalysis: Analyse compl√®te de fermeture
        """
        validate_distance_km(total_distance_km)
        
        # D√©termination du type de cheminement
        initial_point = altitudes[0].point_id
        final_point = altitudes[-1].point_id
        
        if initial_point == final_point:
            traverse_type = TraverseType.CLOSED
            reference_altitude = altitudes[0].altitude_m
        elif known_final_altitude is not None:
            traverse_type = TraverseType.OPEN
            reference_altitude = known_final_altitude
        else:
            traverse_type = TraverseType.UNKNOWN
            reference_altitude = None
        
        # Calcul de l'erreur de fermeture
        if reference_altitude is not None:
            calculated_final = altitudes[-1].altitude_m
            closure_error_m = calculated_final - reference_altitude
            closure_error_mm = closure_error_m * 1000
        else:
            closure_error_m = 0.0
            closure_error_mm = 0.0
        
        # Calcul de la tol√©rance g√©od√©sique: T = 4√ó‚àöK (mm)
        tolerance_mm = 4 * np.sqrt(total_distance_km)
        
        # Validation
        is_acceptable = abs(closure_error_mm) <= tolerance_mm
        precision_ratio = abs(closure_error_mm) / tolerance_mm if tolerance_mm > 0 else 0
        
        return ClosureAnalysis(
            traverse_type=traverse_type,
            closure_error_m=closure_error_m,
            closure_error_mm=closure_error_mm,
            tolerance_mm=tolerance_mm,
            total_distance_km=total_distance_km,
            is_acceptable=is_acceptable,
            precision_ratio=precision_ratio
        )
    
    def get_closure_report(self, closure: ClosureAnalysis) -> str:
        """G√©n√®re un rapport de fermeture d√©taill√©."""
        report = f"""
=== ANALYSE DE FERMETURE ===
üéØ Type de cheminement: {closure.traverse_type.value}
üìè Distance totale: {closure.total_distance_km:.3f} km

üìä Erreur de fermeture:
   Valeur: {closure.closure_error_mm:.2f} mm
   Tol√©rance: ¬±{closure.tolerance_mm:.2f} mm
   Ratio: {closure.precision_ratio:.2f}

‚úÖ Statut: {'ACCEPTABLE' if closure.is_acceptable else 'D√âPASSEMENT'}
üéØ Objectif 2mm: {'ATTEINT' if abs(closure.closure_error_mm) <= 2.0 else 'D√âPASS√â'}
"""
        return report


class LevelingCalculator:
    """
    Calculateur principal int√©grant tous les modules de calcul.
    
    Orchestre l'ensemble des calculs de compensation altim√©trique
    avec validation continue et gestion d'erreurs.
    """
    
    def __init__(self, precision_mm: float = 2.0,
                 instrumental_error_mm: float = 1.0,
                 kilometric_error_mm: float = 1.0,
                 apply_atmospheric_corrections: bool = True,
                 atmospheric_conditions: AtmosphericConditions = None):
        """
        Args:
            precision_mm: Pr√©cision cible (mm)
            instrumental_error_mm: Erreur instrumentale (mm)
            kilometric_error_mm: Erreur kilom√©trique (mm/km)
            apply_atmospheric_corrections: Appliquer corrections atmosph√©riques
            atmospheric_conditions: Conditions atmosph√©riques
        """
        self.precision_mm = precision_mm
        self.apply_atmospheric_corrections = apply_atmospheric_corrections
        
        # Modules de calcul
        self.height_diff_calc = HeightDifferenceCalculator(precision_mm)
        self.altitude_calc = AltitudeCalculator(precision_mm)
        self.weight_calc = WeightCalculator(instrumental_error_mm, kilometric_error_mm)
        self.closure_calc = ClosureCalculator(precision_mm)
        
        # Module corrections atmosph√©riques
        self.atmospheric_corrector = AtmosphericCorrector()
        self.atmospheric_conditions = atmospheric_conditions or create_standard_conditions("france")
        
        # Validateurs
        self.precision_validator = PrecisionValidator(precision_mm)
        self.geodetic_validator = GeodeticValidator()
    
    def calculate_complete_leveling(self, df: pd.DataFrame,
                                  ar_columns: List[str],
                                  av_columns: List[str],
                                  dist_columns: List[str],
                                  initial_altitude: float,
                                  known_final_altitude: Optional[float] = None) -> CalculationResults:
        """
        Calcul complet de nivellement g√©om√©trique avec corrections atmosph√©riques.
        
        Pipeline complet:
        1. Calcul des d√©nivel√©es
        2. Application corrections atmosph√©riques
        3. Calcul des altitudes
        4. Analyse de fermeture
        5. Calcul des poids
        6. Validation de pr√©cision
        
        Args:
            df: DataFrame des observations
            ar_columns: Colonnes AR
            av_columns: Colonnes AV
            dist_columns: Colonnes distances
            initial_altitude: Altitude de r√©f√©rence
            known_final_altitude: Altitude finale connue (si cheminement ouvert)
            
        Returns:
            CalculationResults: R√©sultats complets
        """
        try:
            # 1. Calcul des d√©nivel√©es
            height_differences = self.height_diff_calc.calculate_height_differences(
                df, ar_columns, av_columns
            )
            
            # 1.5. Application des corrections atmosph√©riques si activ√©es
            if self.apply_atmospheric_corrections:
                print("üå°Ô∏è Application des corrections atmosph√©riques...")
                df_corrected = self.atmospheric_corrector.apply_corrections_to_dataframe(
                    df, ar_columns, av_columns, dist_columns, self.atmospheric_conditions
                )
                
                # Utiliser les d√©nivel√©es corrig√©es
                if 'delta_h_final' in df_corrected.columns:
                    mean_deltas = df_corrected['delta_h_final']
                    
                    # Recalculer les height_differences avec corrections
                    corrected_height_differences = []
                    for i, hd in enumerate(height_differences):
                        if i < len(mean_deltas) and pd.notna(mean_deltas.iloc[i]):
                            # Cr√©er une nouvelle HeightDifference avec valeur corrig√©e
                            corrected_hd = HeightDifference(
                                delta_h_m=mean_deltas.iloc[i],
                                ar_reading=hd.ar_reading,
                                av_reading=hd.av_reading,
                                instrument_id=hd.instrument_id,
                                is_valid=hd.is_valid,
                                control_residual=hd.control_residual
                            )
                            corrected_height_differences.append(corrected_hd)
                        else:
                            corrected_height_differences.append(hd)
                    
                    height_differences = corrected_height_differences
                    print(f"   ‚úÖ Corrections appliqu√©es √† {len(mean_deltas)} observations")
                else:
                    # Fallback : moyennes normales
                    mean_deltas = self.height_diff_calc.get_mean_height_differences(height_differences)
                    print("   ‚ö†Ô∏è Fallback : d√©nivel√©es non corrig√©es utilis√©es")
            else:
                # Obtenir les d√©nivel√©es moyennes sans corrections
                mean_deltas = self.height_diff_calc.get_mean_height_differences(height_differences)
                print("üîß Corrections atmosph√©riques d√©sactiv√©es")
            
            # 2. Calcul des altitudes
            altitudes = self.altitude_calc.calculate_altitudes(
                initial_altitude, mean_deltas, df['Matricule']
            )
            
            # 3. Calcul de la distance totale
            if dist_columns:
                total_distance_m = df[dist_columns[0]].sum()
                total_distance_km = total_distance_m / 1000
            else:
                # Distance par d√©faut bas√©e sur le nombre de points
                total_distance_km = len(df) * 0.1  # 100m par segment
            
            # 4. Analyse de fermeture
            closure_analysis = self.closure_calc.analyze_closure(
                altitudes, total_distance_km, known_final_altitude
            )
            
            # 5. Statistiques de contr√¥le
            control_stats = self._calculate_control_statistics(height_differences)
            
            # 6. M√©tadonn√©es des calculs
            metadata = {
                'calculation_timestamp': pd.Timestamp.now(),
                'precision_target_mm': self.precision_mm,
                'total_points': len(df),
                'total_observations': len(height_differences),
                'ar_columns_used': ar_columns,
                'av_columns_used': av_columns,
                'dist_columns_used': dist_columns,
                'atmospheric_corrections_applied': self.apply_atmospheric_corrections,
                'atmospheric_conditions': {
                    'temperature_c': self.atmospheric_conditions.temperature_celsius,
                    'pressure_hpa': self.atmospheric_conditions.pressure_hpa,
                    'humidity_percent': self.atmospheric_conditions.humidity_percent
                } if self.apply_atmospheric_corrections else None,
                'altitude_statistics': self.altitude_calc.validate_altitude_consistency(altitudes)
            }
            
            return CalculationResults(
                height_differences=height_differences,
                altitudes=altitudes,
                closure_analysis=closure_analysis,
                control_statistics=control_stats,
                calculation_metadata=metadata
            )
            
        except Exception as e:
            raise CalculationError(
                f"Erreur dans le calcul complet: {str(e)}",
                calculation_type="complete_leveling"
            )
    
    def _calculate_control_statistics(self, height_differences: List[HeightDifference]) -> Dict:
        """Calcul des statistiques de contr√¥le."""
        residuals = [hd.control_residual for hd in height_differences 
                    if hd.control_residual is not None]
        
        if not residuals:
            return {'no_control_data': True}
        
        residuals = np.array(residuals)
        
        return {
            'residual_count': len(residuals),
            'max_residual_mm': np.max(np.abs(residuals)) * 1000,
            'mean_residual_mm': np.mean(np.abs(residuals)) * 1000,
            'std_residual_mm': np.std(residuals) * 1000,
            'points_exceeding_5mm': np.sum(np.abs(residuals) * 1000 > 5.0),
            'control_quality': 'GOOD' if np.max(np.abs(residuals)) * 1000 <= 3.0 else 'WARNING'
        }
    
    def generate_calculation_report(self, results: CalculationResults) -> str:
        """G√©n√®re un rapport complet des calculs."""
        report = f"""
{'='*60}
    RAPPORT DE CALCULS - NIVELLEMENT G√âOM√âTRIQUE
{'='*60}

üéØ OBJECTIF DE PR√âCISION: {self.precision_mm} mm

üìä STATISTIQUES G√âN√âRALES:
   Points: {results.calculation_metadata['total_points']}
   Observations: {results.calculation_metadata['total_observations']}
   Colonnes AR: {', '.join(results.calculation_metadata['ar_columns_used'])}
   Colonnes AV: {', '.join(results.calculation_metadata['av_columns_used'])}

üìê D√âNIVEL√âES CALCUL√âES:
   Valides: {sum(1 for hd in results.height_differences if hd.is_valid)}
   Invalides: {sum(1 for hd in results.height_differences if not hd.is_valid)}
   
üìè ALTITUDES:
   R√©f√©rence: {results.altitudes[0].altitude_m:.3f} m
   Finale: {results.altitudes[-1].altitude_m:.3f} m
   D√©nivel√©e totale: {results.altitudes[-1].cumulative_delta_h:.3f} m

{self.closure_calc.get_closure_report(results.closure_analysis)}

üîß CONTR√îLE QUALIT√â:
   Statut: {results.control_statistics.get('control_quality', 'N/A')}
   R√©sidu max: {results.control_statistics.get('max_residual_mm', 0):.2f} mm
   Points > 5mm: {results.control_statistics.get('points_exceeding_5mm', 0)}

‚úÖ VALIDATION FINALE:
   Fermeture: {'‚úÖ OK' if results.closure_analysis.is_acceptable else '‚ùå PROBL√àME'}
   Pr√©cision 2mm: {'‚úÖ ATTEINTE' if abs(results.closure_analysis.closure_error_mm) <= 2.0 else '‚ùå D√âPASS√âE'}
   
Rapport g√©n√©r√© le: {results.calculation_metadata['calculation_timestamp']}
{'='*60}
"""
        return report
    
    def export_results_to_dataframe(self, results: CalculationResults) -> pd.DataFrame:
        """Export des r√©sultats vers un DataFrame."""
        # Cr√©er un DataFrame avec les r√©sultats principaux
        data = []
        
        for i, altitude in enumerate(results.altitudes):
            row = {
                'Matricule': altitude.point_id,
                'Altitude_m': altitude.altitude_m,
                'Delta_h_cumul√©': altitude.cumulative_delta_h,
                'Est_r√©f√©rence': altitude.is_reference
            }
            
            # Ajouter les d√©nivel√©es si disponibles
            if i < len(results.height_differences):
                hd = results.height_differences[i]
                row.update({
                    'AR_lecture': hd.ar_reading,
                    'AV_lecture': hd.av_reading,
                    'Delta_h': hd.delta_h_m,
                    'Controle_residuel': hd.control_residual,
                    'Observation_valide': hd.is_valid
                })
            
            data.append(row)
        
        return pd.DataFrame(data)


# Fonctions utilitaires
def quick_leveling_calculation(df: pd.DataFrame, 
                             initial_altitude: float,
                             precision_mm: float = 2.0) -> CalculationResults:
    """Calcul rapide avec d√©tection automatique des colonnes."""
    from data_importer import DataImporter
    
    # Import et validation automatique
    importer = DataImporter()
    importer.validator = DataImporter().validator
    validation_result = importer.validator.validate_dataframe(df)
    
    if not validation_result.is_valid:
        raise CalculationError(
            f"Donn√©es invalides: {'; '.join(validation_result.errors)}",
            calculation_type="quick_calculation"
        )
    
    # Extraction des colonnes
    ar_columns = validation_result.details.get('ar_columns', [])
    av_columns = validation_result.details.get('av_columns', [])
    dist_columns = validation_result.details.get('dist_columns', [])
    
    # Calcul
    calculator = LevelingCalculator(precision_mm)
    return calculator.calculate_complete_leveling(
        df, ar_columns, av_columns, dist_columns, initial_altitude
    )


def validate_calculation_inputs(df: pd.DataFrame, 
                              ar_columns: List[str],
                              av_columns: List[str],
                              initial_altitude: float) -> bool:
    """Validation rapide des entr√©es de calcul."""
    try:
        # V√©rifications de base
        if df.empty:
            return False
        
        if len(ar_columns) != len(av_columns):
            return False
        
        if not all(col in df.columns for col in ar_columns + av_columns):
            return False
        
        validate_positive_number(initial_altitude, "altitude_initiale", allow_zero=True)
        
        return True
        
    except:
        return False