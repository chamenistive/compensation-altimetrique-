"""
Module d'importation des donnÃ©es pour la compensation altimÃ©trique.

Ce module gÃ¨re l'importation, la validation et la prÃ©paration des donnÃ©es
de nivellement depuis diffÃ©rents formats (Excel, CSV, etc.).

Algorithmes implÃ©mentÃ©s:
- Importation robuste Excel/CSV
- DÃ©tection automatique des colonnes AR/AV/DIST
- Validation structure et cohÃ©rence des donnÃ©es
- PrÃ©paration pour compensation (nettoyage, indexation)

Auteur: SystÃ¨me de Compensation AltimÃ©trique
Version: 1.0
PrÃ©cision: 2mm
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Union
from dataclasses import dataclass

from exceptions import FileImportError, DataValidationError
from validators import DataStructureValidator, ValidationResult


@dataclass
class ImportedData:
    """Structure pour les donnÃ©es importÃ©es."""
    dataframe: pd.DataFrame
    ar_columns: List[str]
    av_columns: List[str]
    dist_columns: List[str]
    initial_point: str
    final_point: str
    metadata: Dict
    validation_result: ValidationResult


class DataImporter:
    """
    Importeur de donnÃ©es pour la compensation altimÃ©trique.
    
    GÃ¨re l'importation depuis Excel/CSV avec validation automatique
    et prÃ©paration des donnÃ©es pour les calculs de compensation.
    """
    
    SUPPORTED_FORMATS = ['.xlsx', '.xls', '.csv']
    DEFAULT_ENCODING = 'utf-8'
    
    def __init__(self):
        self.validator = DataStructureValidator()
        self.last_import_result = None
    
    def import_file(self, filepath: Union[str, Path], 
                   sheet_name: Optional[str] = None,
                   header_row: int = 0,
                   encoding: str = None) -> ImportedData:
        """
        Importe un fichier de donnÃ©es de nivellement.
        
        Args:
            filepath: Chemin vers le fichier
            sheet_name: Nom de la feuille Excel (None = premiÃ¨re feuille)
            header_row: Ligne d'en-tÃªte (0 = premiÃ¨re ligne)
            encoding: Encodage pour les CSV (None = auto-dÃ©tection)
            
        Returns:
            ImportedData: DonnÃ©es importÃ©es et validÃ©es
            
        Raises:
            FileImportError: Erreur lors de l'importation
            DataValidationError: DonnÃ©es non conformes
        """
        filepath = Path(filepath)
        
        # Validation du fichier
        self._validate_file(filepath)
        
        try:
            # Importation selon le format
            if filepath.suffix.lower() in ['.xlsx', '.xls']:
                df = self._import_excel(filepath, sheet_name, header_row)
            elif filepath.suffix.lower() == '.csv':
                df = self._import_csv(filepath, encoding, header_row)
            else:
                raise FileImportError(
                    f"Format non supportÃ©: {filepath.suffix}",
                    filename=str(filepath),
                    file_type=filepath.suffix
                )
            
            # PrÃ©paration et validation
            prepared_data = self._prepare_data(df, filepath)
            
            # Sauvegarde du rÃ©sultat
            self.last_import_result = prepared_data
            
            return prepared_data
            
        except Exception as e:
            if isinstance(e, (FileImportError, DataValidationError)):
                raise
            else:
                raise FileImportError(
                    f"Erreur inattendue lors de l'importation: {str(e)}",
                    filename=str(filepath)
                )
    
    def _validate_file(self, filepath: Path):
        """Validation du fichier avant importation."""
        if not filepath.exists():
            raise FileImportError(
                f"Fichier non trouvÃ©: {filepath}",
                filename=str(filepath)
            )
        
        if filepath.suffix.lower() not in self.SUPPORTED_FORMATS:
            raise FileImportError(
                f"Format non supportÃ©: {filepath.suffix}. "
                f"Formats acceptÃ©s: {', '.join(self.SUPPORTED_FORMATS)}",
                filename=str(filepath),
                file_type=filepath.suffix
            )
        
        if filepath.stat().st_size == 0:
            raise FileImportError(
                "Fichier vide",
                filename=str(filepath)
            )
        
        if filepath.stat().st_size > 100 * 1024 * 1024:  # 100 MB
            raise FileImportError(
                f"Fichier trop volumineux: {filepath.stat().st_size / (1024*1024):.1f} MB > 100 MB",
                filename=str(filepath)
            )
    
    def _import_excel(self, filepath: Path, sheet_name: Optional[str], 
                     header_row: int) -> pd.DataFrame:
        """Importation depuis Excel."""
        try:
            # Lecture du fichier Excel
            df = pd.read_excel(
                filepath,
                sheet_name=sheet_name,
                header=header_row,
                engine='openpyxl' if filepath.suffix.lower() == '.xlsx' else None
            )
            
            # Si sheet_name=None, pandas retourne un dict avec toutes les feuilles
            if isinstance(df, dict):
                # Prendre la premiÃ¨re feuille
                sheet_names = list(df.keys())
                if not sheet_names:
                    raise FileImportError(
                        "Aucune feuille trouvÃ©e dans le fichier Excel",
                        filename=str(filepath),
                        file_type="Excel"
                    )
                df = df[sheet_names[0]]  # Prendre la premiÃ¨re feuille
            
            if df.empty:
                raise FileImportError(
                    "Feuille Excel vide ou aucune donnÃ©e trouvÃ©e",
                    filename=str(filepath)
                )
            
            return df
            
        except pd.errors.EmptyDataError:
            raise FileImportError(
                "Fichier Excel vide ou corrompu",
                filename=str(filepath),
                file_type="Excel"
            )
        except pd.errors.ParserError as e:
            raise FileImportError(
                f"Erreur de lecture Excel: {str(e)}",
                filename=str(filepath),
                file_type="Excel"
            )
        except Exception as e:
            raise FileImportError(
                f"Erreur Excel inattendue: {str(e)}",
                filename=str(filepath),
                file_type="Excel"
            )
    
    def _import_csv(self, filepath: Path, encoding: Optional[str], 
                   header_row: int) -> pd.DataFrame:
        """Importation depuis CSV avec dÃ©tection automatique de l'encodage."""
        if encoding is None:
            encoding = self._detect_encoding(filepath)
        
        try:
            # Tentative de lecture avec diffÃ©rents sÃ©parateurs
            separators = [',', ';', '\t', '|']
            df = None
            
            for sep in separators:
                try:
                    df = pd.read_csv(
                        filepath,
                        sep=sep,
                        header=header_row,
                        encoding=encoding
                    )
                    
                    # VÃ©rifier si la lecture a du sens (plus d'une colonne)
                    if len(df.columns) > 1 and not df.empty:
                        break
                except:
                    continue
            
            if df is None or df.empty:
                raise FileImportError(
                    "Impossible de lire le fichier CSV ou fichier vide",
                    filename=str(filepath),
                    file_type="CSV"
                )
            
            return df
            
        except UnicodeDecodeError:
            raise FileImportError(
                f"ProblÃ¨me d'encodage. Essayez avec encoding='latin1' ou 'cp1252'",
                filename=str(filepath),
                file_type="CSV"
            )
        except Exception as e:
            raise FileImportError(
                f"Erreur CSV: {str(e)}",
                filename=str(filepath),
                file_type="CSV"
            )
    
    def _detect_encoding(self, filepath: Path) -> str:
        """DÃ©tection automatique de l'encodage."""
        encodings_to_try = ['utf-8', 'latin1', 'cp1252', 'iso-8859-1']
        
        for encoding in encodings_to_try:
            try:
                with open(filepath, 'r', encoding=encoding) as f:
                    f.read(1024)  # Essayer de lire les premiers 1024 caractÃ¨res
                return encoding
            except UnicodeDecodeError:
                continue
        
        # Si aucun encodage ne fonctionne, utiliser utf-8 par dÃ©faut
        return 'utf-8'
    
    def _prepare_data(self, df: pd.DataFrame, filepath: Path) -> ImportedData:
        """PrÃ©paration et validation des donnÃ©es importÃ©es."""
        # 1. Nettoyage initial
        df = self._clean_dataframe(df)
        
        # 2. Validation structure
        validation_result = self.validator.validate_dataframe(df)
        
        if not validation_result.is_valid:
            raise DataValidationError(
                f"Validation Ã©chouÃ©e: {'; '.join(validation_result.errors)}",
                invalid_data={'fichier': str(filepath)}
            )
        
        # 3. Extraction des informations
        ar_columns = validation_result.details.get('ar_columns', [])
        av_columns = validation_result.details.get('av_columns', [])
        dist_columns = validation_result.details.get('dist_columns', [])
        
        # 4. Identification des points initial et final
        initial_point, final_point = self._identify_endpoints(df)
        
        # 5. MÃ©tadonnÃ©es
        metadata = {
            'source_file': str(filepath),
            'import_timestamp': pd.Timestamp.now(),
            'total_points': len(df),
            'total_columns': len(df.columns),
            'file_size_bytes': filepath.stat().st_size,
            'statistics': validation_result.details.get('statistics', {})
        }
        
        return ImportedData(
            dataframe=df,
            ar_columns=ar_columns,
            av_columns=av_columns,
            dist_columns=dist_columns,
            initial_point=initial_point,
            final_point=final_point,
            metadata=metadata,
            validation_result=validation_result
        )
    
    def _clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """Nettoyage du DataFrame."""
        # Nettoyer les noms de colonnes
        df.columns = df.columns.astype(str).str.strip()
        
        # Supprimer les lignes entiÃ¨rement vides
        df = df.dropna(how='all')
        
        # Supprimer les colonnes entiÃ¨rement vides
        df = df.dropna(axis=1, how='all')
        
        # RÃ©indexer proprement
        df = df.reset_index(drop=True)
        
        # Supprimer les lignes sans Matricule (si la colonne existe)
        if 'Matricule' in df.columns:
            df = df.dropna(subset=['Matricule']).reset_index(drop=True)
        
        return df
    
    def _identify_endpoints(self, df: pd.DataFrame) -> Tuple[str, str]:
        """Identification des points initial et final."""
        if 'Matricule' not in df.columns:
            raise DataValidationError("Colonne 'Matricule' manquante pour identifier les points")
        
        matricules = df['Matricule'].dropna()
        if matricules.empty:
            raise DataValidationError("Aucun matricule valide trouvÃ©")
        
        initial_point = str(matricules.iloc[0])
        final_point = str(matricules.iloc[-1])
        
        return initial_point, final_point
    
    def get_import_summary(self) -> str:
        """RÃ©sumÃ© de la derniÃ¨re importation."""
        if self.last_import_result is None:
            return "Aucune importation effectuÃ©e"
        
        data = self.last_import_result
        summary = f"""
=== RÃ‰SUMÃ‰ D'IMPORTATION ===
ðŸ“ Fichier: {data.metadata['source_file']}
ðŸ“Š Points: {data.metadata['total_points']}
ðŸ“‹ Colonnes: {data.metadata['total_columns']}
ðŸ“ Taille: {data.metadata['file_size_bytes'] / 1024:.1f} KB

ðŸŽ¯ Points de cheminement:
   Initial: {data.initial_point}
   Final: {data.final_point}
   Type: {'FermÃ©' if data.initial_point == data.final_point else 'Ouvert'}

ðŸ“ Colonnes dÃ©tectÃ©es:
   AR: {len(data.ar_columns)} ({', '.join(data.ar_columns)})
   AV: {len(data.av_columns)} ({', '.join(data.av_columns)})
   DIST: {len(data.dist_columns)} ({', '.join(data.dist_columns)})

{data.validation_result.get_summary()}
"""
        return summary
    
    def export_prepared_data(self, output_path: Union[str, Path], 
                           format: str = 'excel') -> Path:
        """
        Export des donnÃ©es prÃ©parÃ©es.
        
        Args:
            output_path: Chemin de sortie
            format: Format ('excel' ou 'csv')
            
        Returns:
            Path: Chemin du fichier exportÃ©
        """
        if self.last_import_result is None:
            raise DataValidationError("Aucune donnÃ©e Ã  exporter")
        
        output_path = Path(output_path)
        df = self.last_import_result.dataframe
        
        try:
            if format.lower() == 'excel':
                if not output_path.suffix:
                    output_path = output_path.with_suffix('.xlsx')
                df.to_excel(output_path, index=False)
            elif format.lower() == 'csv':
                if not output_path.suffix:
                    output_path = output_path.with_suffix('.csv')
                df.to_csv(output_path, index=False, encoding='utf-8')
            else:
                raise ValueError(f"Format non supportÃ©: {format}")
            
            return output_path
            
        except Exception as e:
            raise FileImportError(
                f"Erreur lors de l'export: {str(e)}",
                filename=str(output_path)
            )


# Fonctions utilitaires
def quick_import(filepath: Union[str, Path], **kwargs) -> ImportedData:
    """Import rapide avec paramÃ¨tres par dÃ©faut."""
    importer = DataImporter()
    return importer.import_file(filepath, **kwargs)


def validate_file_format(filepath: Union[str, Path]) -> bool:
    """Validation rapide du format de fichier."""
    try:
        filepath = Path(filepath)
        return filepath.suffix.lower() in DataImporter.SUPPORTED_FORMATS
    except:
        return False